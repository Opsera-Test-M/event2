# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤ Canary Deployment Pipeline - Plan & Joy
# Progressive rollout: 10% â†’ 30% â†’ 60% â†’ 100%
# Generated by Opsera Code-to-Cloud v4.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
name: "ğŸ¤ Canary Deploy - plan-and-joy"

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment for canary'
        required: true
        default: 'qa'
        type: choice
        options:
          - qa
          - staging
          - prod
      skip_quality_gates:
        description: 'Skip quality gates (emergency only)'
        required: false
        default: false
        type: boolean
      auto_promote:
        description: 'Auto-promote through all phases'
        required: false
        default: true
        type: boolean
      phase_delay_minutes:
        description: 'Minutes to wait between phases'
        required: false
        default: '5'
        type: string

env:
  APP_NAME: plan-and-joy
  TENANT: opsera
  AWS_REGION: us-west-2
  ENVIRONMENT: ${{ github.event.inputs.environment || 'qa' }}
  DOMAIN: agent.opsera.dev

concurrency:
  group: canary-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 1: Build & Push Canary Image
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  build-canary:
    name: "ğŸ—ï¸ Build Canary"
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.build.outputs.image_tag }}
      full_image: ${{ steps.build.outputs.full_image }}
      ecr_uri: ${{ steps.ecr.outputs.uri }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get ECR URI
        id: ecr
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.TENANT }}/${{ env.APP_NAME }}"
          echo "uri=$ECR_URI" >> $GITHUB_OUTPUT

      - name: Login to ECR
        run: |
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | \
            docker login --username AWS --password-stdin ${{ steps.ecr.outputs.uri }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and Push Canary Image
        id: build
        env:
          ECR_URI: ${{ steps.ecr.outputs.uri }}
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          VITE_SUPABASE_PUBLISHABLE_KEY: ${{ secrets.VITE_SUPABASE_PUBLISHABLE_KEY }}
        run: |
          IMAGE_TAG="canary-${GITHUB_SHA:0:7}-$(date +%Y%m%d%H%M%S)"
          FULL_IMAGE="${ECR_URI}:${IMAGE_TAG}"

          echo "ğŸ¤ Building canary image: $FULL_IMAGE"

          docker build \
            --build-arg VITE_SUPABASE_URL="${VITE_SUPABASE_URL}" \
            --build-arg VITE_SUPABASE_PUBLISHABLE_KEY="${VITE_SUPABASE_PUBLISHABLE_KEY}" \
            -t "$FULL_IMAGE" \
            -f .opsera-${{ env.APP_NAME }}/Dockerfile \
            .

          docker push "$FULL_IMAGE"

          echo "image_tag=$IMAGE_TAG" >> $GITHUB_OUTPUT
          echo "full_image=$FULL_IMAGE" >> $GITHUB_OUTPUT
          echo "âœ… Canary image pushed: $FULL_IMAGE"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 2: Quality Gates (Grype + SonarQube)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  quality-gates:
    name: "ğŸ”’ Quality Gates"
    runs-on: ubuntu-latest
    needs: build-canary
    if: ${{ github.event.inputs.skip_quality_gates != 'true' }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to ECR
        run: |
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | \
            docker login --username AWS --password-stdin ${{ needs.build-canary.outputs.ecr_uri }}

      - name: Pull Canary Image
        run: docker pull ${{ needs.build-canary.outputs.full_image }}

      - name: Install Grype
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin

      - name: Run Grype Scan
        run: |
          echo "ğŸ”’ Scanning canary image for vulnerabilities..."
          grype ${{ needs.build-canary.outputs.full_image }} --fail-on critical --output table
          echo "âœ… Security scan passed - no critical vulnerabilities"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 3: Deploy Canary (10% Traffic)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  canary-phase-1:
    name: "ğŸ¤ Phase 1: 10% Traffic"
    runs-on: ubuntu-latest
    needs: [build-canary, quality-gates]
    if: always() && needs.build-canary.result == 'success' && (needs.quality-gates.result == 'success' || needs.quality-gates.result == 'skipped')
    outputs:
      canary_healthy: ${{ steps.health.outputs.healthy }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}
          fetch-depth: 0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Connect to EKS
        run: aws eks update-kubeconfig --name argocd-usw2 --region ${{ env.AWS_REGION }}

      - name: Deploy Canary Pods
        env:
          ECR_URI: ${{ needs.build-canary.outputs.ecr_uri }}
          IMAGE_TAG: ${{ needs.build-canary.outputs.image_tag }}
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          echo "ğŸ¤ Deploying canary pods..."
          
          # Update canary deployment image
          cat <<EOF | kubectl apply -f -
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: ${{ env.APP_NAME }}-canary
            namespace: $NAMESPACE
            labels:
              app: ${{ env.APP_NAME }}
              version: canary
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: ${{ env.APP_NAME }}
                version: canary
            template:
              metadata:
                labels:
                  app: ${{ env.APP_NAME }}
                  version: canary
              spec:
                containers:
                  - name: ${{ env.APP_NAME }}
                    image: ${ECR_URI}:${IMAGE_TAG}
                    ports:
                      - containerPort: 8080
                    resources:
                      requests:
                        cpu: "50m"
                        memory: "64Mi"
                      limits:
                        cpu: "500m"
                        memory: "512Mi"
                    readinessProbe:
                      httpGet:
                        path: /
                        port: 8080
                      initialDelaySeconds: 5
                      periodSeconds: 5
          EOF

          # Create canary service
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: Service
          metadata:
            name: ${{ env.APP_NAME }}-canary
            namespace: $NAMESPACE
          spec:
            selector:
              app: ${{ env.APP_NAME }}
              version: canary
            ports:
              - port: 80
                targetPort: 8080
          EOF

          echo "âœ… Canary pods deployed"

      - name: Set Canary Traffic to 10%
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          HOST="${{ env.TENANT }}-${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}.${{ env.DOMAIN }}"
          
          echo "ğŸš¦ Setting canary traffic to 10%..."
          
          cat <<EOF | kubectl apply -f -
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: ${{ env.APP_NAME }}-canary
            namespace: $NAMESPACE
            annotations:
              nginx.ingress.kubernetes.io/canary: "true"
              nginx.ingress.kubernetes.io/canary-weight: "10"
          spec:
            ingressClassName: nginx
            tls:
              - hosts:
                  - $HOST
                secretName: ${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}-tls
            rules:
              - host: $HOST
                http:
                  paths:
                    - path: /
                      pathType: Prefix
                      backend:
                        service:
                          name: ${{ env.APP_NAME }}-canary
                          port:
                            number: 80
          EOF
          
          echo "âœ… 10% traffic now routed to canary"

      - name: Wait for Canary Health
        id: health
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          echo "â³ Waiting for canary pods to be healthy..."
          
          kubectl rollout status deployment/${{ env.APP_NAME }}-canary -n $NAMESPACE --timeout=120s
          
          if [ $? -eq 0 ]; then
            echo "healthy=true" >> $GITHUB_OUTPUT
            echo "âœ… Canary pods healthy"
          else
            echo "healthy=false" >> $GITHUB_OUTPUT
            echo "âŒ Canary pods not healthy"
            exit 1
          fi

      - name: Display Phase 1 Status
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘  ğŸ¤ CANARY PHASE 1 COMPLETE                                  â•‘"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
          echo "â•‘  Traffic: 10% â†’ Canary | 90% â†’ Stable                        â•‘"
          echo "â•‘  Status:  âœ… Healthy                                          â•‘"
          echo "â•‘  Next:    Phase 2 (30%) in ${{ github.event.inputs.phase_delay_minutes }} minutes    â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 4: Canary Phase 2 (30% Traffic)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  canary-phase-2:
    name: "ğŸ¤ Phase 2: 30% Traffic"
    runs-on: ubuntu-latest
    needs: [build-canary, canary-phase-1]
    if: needs.canary-phase-1.outputs.canary_healthy == 'true'
    outputs:
      canary_healthy: ${{ steps.health.outputs.healthy }}
    steps:
      - name: Wait Before Phase 2
        run: |
          echo "â³ Waiting ${{ github.event.inputs.phase_delay_minutes }} minutes before Phase 2..."
          sleep $(( ${{ github.event.inputs.phase_delay_minutes }} * 60 ))

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Connect to EKS
        run: aws eks update-kubeconfig --name argocd-usw2 --region ${{ env.AWS_REGION }}

      - name: Increase Traffic to 30%
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          echo "ğŸš¦ Increasing canary traffic to 30%..."
          
          kubectl patch ingress ${{ env.APP_NAME }}-canary -n $NAMESPACE \
            -p '{"metadata":{"annotations":{"nginx.ingress.kubernetes.io/canary-weight":"30"}}}'
          
          echo "âœ… 30% traffic now routed to canary"

      - name: Validate Canary Health
        id: health
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          READY=$(kubectl get deployment ${{ env.APP_NAME }}-canary -n $NAMESPACE -o jsonpath='{.status.readyReplicas}')
          
          if [ "$READY" -ge 1 ]; then
            echo "healthy=true" >> $GITHUB_OUTPUT
            echo "âœ… Canary still healthy at 30% traffic"
          else
            echo "healthy=false" >> $GITHUB_OUTPUT
            echo "âŒ Canary unhealthy - triggering rollback"
            exit 1
          fi

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 5: Canary Phase 3 (60% Traffic)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  canary-phase-3:
    name: "ğŸ¤ Phase 3: 60% Traffic"
    runs-on: ubuntu-latest
    needs: [build-canary, canary-phase-2]
    if: needs.canary-phase-2.outputs.canary_healthy == 'true'
    outputs:
      canary_healthy: ${{ steps.health.outputs.healthy }}
    steps:
      - name: Wait Before Phase 3
        run: |
          echo "â³ Waiting ${{ github.event.inputs.phase_delay_minutes }} minutes before Phase 3..."
          sleep $(( ${{ github.event.inputs.phase_delay_minutes }} * 60 ))

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Connect to EKS
        run: aws eks update-kubeconfig --name argocd-usw2 --region ${{ env.AWS_REGION }}

      - name: Increase Traffic to 60%
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          echo "ğŸš¦ Increasing canary traffic to 60%..."
          
          kubectl patch ingress ${{ env.APP_NAME }}-canary -n $NAMESPACE \
            -p '{"metadata":{"annotations":{"nginx.ingress.kubernetes.io/canary-weight":"60"}}}'
          
          echo "âœ… 60% traffic now routed to canary"

      - name: Validate Canary Health
        id: health
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          READY=$(kubectl get deployment ${{ env.APP_NAME }}-canary -n $NAMESPACE -o jsonpath='{.status.readyReplicas}')
          
          if [ "$READY" -ge 1 ]; then
            echo "healthy=true" >> $GITHUB_OUTPUT
            echo "âœ… Canary still healthy at 60% traffic"
          else
            echo "healthy=false" >> $GITHUB_OUTPUT
            echo "âŒ Canary unhealthy - triggering rollback"
            exit 1
          fi

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 6: Full Promotion (100% Traffic)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  promote-canary:
    name: "ğŸš€ Promote to 100%"
    runs-on: ubuntu-latest
    needs: [build-canary, canary-phase-3]
    if: needs.canary-phase-3.outputs.canary_healthy == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}
          fetch-depth: 0

      - name: Wait Before Promotion
        run: |
          echo "â³ Waiting ${{ github.event.inputs.phase_delay_minutes }} minutes before full promotion..."
          sleep $(( ${{ github.event.inputs.phase_delay_minutes }} * 60 ))

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Connect to EKS
        run: aws eks update-kubeconfig --name argocd-usw2 --region ${{ env.AWS_REGION }}

      - name: Promote Canary to Stable
        env:
          ECR_URI: ${{ needs.build-canary.outputs.ecr_uri }}
          IMAGE_TAG: ${{ needs.build-canary.outputs.image_tag }}
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          echo "ğŸš€ Promoting canary to stable..."
          
          # Update stable deployment to canary image
          kubectl set image deployment/${{ env.APP_NAME }} \
            ${{ env.APP_NAME }}=${ECR_URI}:${IMAGE_TAG} \
            -n $NAMESPACE
          
          # Wait for rollout
          kubectl rollout status deployment/${{ env.APP_NAME }} -n $NAMESPACE --timeout=180s
          
          echo "âœ… Stable deployment updated to canary version"

      - name: Remove Canary Resources
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          echo "ğŸ§¹ Cleaning up canary resources..."
          
          kubectl delete ingress ${{ env.APP_NAME }}-canary -n $NAMESPACE --ignore-not-found
          kubectl delete service ${{ env.APP_NAME }}-canary -n $NAMESPACE --ignore-not-found
          kubectl delete deployment ${{ env.APP_NAME }}-canary -n $NAMESPACE --ignore-not-found
          
          echo "âœ… Canary resources cleaned up"

      - name: Update Kustomization
        run: |
          KUSTOMIZE_FILE=".opsera-${{ env.APP_NAME }}/k8s/overlays/${{ env.ENVIRONMENT }}/kustomization.yaml"
          ECR_URI="${{ needs.build-canary.outputs.ecr_uri }}"
          IMAGE_TAG="${{ needs.build-canary.outputs.image_tag }}"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase origin main

          sed -i "s|newName:.*|newName: $ECR_URI|" "$KUSTOMIZE_FILE"
          sed -i "s|newTag:.*|newTag: $IMAGE_TAG|" "$KUSTOMIZE_FILE"

          git add "$KUSTOMIZE_FILE"
          if ! git diff --staged --quiet; then
            git commit -m "chore: promote canary $IMAGE_TAG to stable [skip ci]"
            git push origin main
          fi

      - name: Display Canary Complete
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘  ğŸ‰ CANARY DEPLOYMENT COMPLETE                                                   â•‘"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
          echo "â•‘  App:         ${{ env.APP_NAME }}"
          echo "â•‘  Environment: ${{ env.ENVIRONMENT }}"
          echo "â•‘  Image:       ${{ needs.build-canary.outputs.image_tag }}"
          echo "â•‘  Strategy:    Canary (10% â†’ 30% â†’ 60% â†’ 100%)"
          echo "â•‘  Status:      âœ… Successfully promoted"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
          echo "â•‘  ğŸŒ URL: https://${{ env.TENANT }}-${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}.${{ env.DOMAIN }}"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Job 7: Rollback (if any phase fails)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  rollback:
    name: "âª Rollback Canary"
    runs-on: ubuntu-latest
    needs: [canary-phase-1, canary-phase-2, canary-phase-3, promote-canary]
    if: failure()
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Connect to EKS
        run: aws eks update-kubeconfig --name argocd-usw2 --region ${{ env.AWS_REGION }}

      - name: Rollback Canary
        run: |
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"
          
          echo "âª Rolling back canary deployment..."
          
          # Delete canary resources
          kubectl delete ingress ${{ env.APP_NAME }}-canary -n $NAMESPACE --ignore-not-found
          kubectl delete service ${{ env.APP_NAME }}-canary -n $NAMESPACE --ignore-not-found
          kubectl delete deployment ${{ env.APP_NAME }}-canary -n $NAMESPACE --ignore-not-found
          
          echo "âœ… Canary resources removed - stable deployment unaffected"
          echo "âš ï¸ Stable deployment continues serving 100% traffic"
